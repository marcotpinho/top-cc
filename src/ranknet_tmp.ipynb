{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f056719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from db_utils import load_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d914ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNetDataset(Dataset):\n",
    "    def __init__(self, data_dir=\"../data\", split=\"train\"):\n",
    "        data_file = f\"{data_dir}/distances_{split}_.json\"\n",
    "        speeds_stats_file = f\"{data_dir}/speeds_stats.json\"\n",
    "        map_stats_file = f\"{data_dir}/map_stats.json\"\n",
    "        print(f\"Loading data from {data_file}...\")\n",
    "\n",
    "        self.split = split\n",
    "        self.X, self.y, self.map_groups = load_from_db(data_file)\n",
    "\n",
    "        with open(speeds_stats_file, 'r') as f:\n",
    "            speeds_stats = json.load(f)\n",
    "            self.std_speed = speeds_stats[\"std_speed\"]\n",
    "            self.mean_speed = speeds_stats[\"mean_speed\"]\n",
    "        with open(map_stats_file, 'r') as f:\n",
    "            map_stats = json.load(f)\n",
    "            self.std_map = map_stats[\"std_map\"]\n",
    "            self.mean_map = map_stats[\"mean_map\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "\n",
    "class RankNetPairDataset(RankNetDataset):\n",
    "    def __init__(self, same_map_pairs=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.same_map_pairs = same_map_pairs\n",
    "    \n",
    "    def __getitem__(self, i1):\n",
    "        x1, y1 = super().__getitem__(i1)\n",
    "        map1 = x1[\"map\"]\n",
    "        \n",
    "        if self.same_map_pairs:\n",
    "            i2 = np.random.choice(self.map_groups[map1])\n",
    "        else:\n",
    "            i2 = np.random.randint(0, len(self.X))\n",
    "\n",
    "        x2, y2 = super().__getitem__(i2)\n",
    "\n",
    "        sp1 = self.normalize_speed(x1[\"speed\"])\n",
    "        sp2 = self.normalize_speed(x2[\"speed\"])\n",
    "        c1 = self.normalize_coord(x1[\"coordinates\"])\n",
    "        c2 = self.normalize_coord(x2[\"coordinates\"])\n",
    "\n",
    "        if y1 > y2:\n",
    "            target = 1.0\n",
    "        elif y1 < y2:\n",
    "            target = 0.0\n",
    "        else:\n",
    "            target = 0.5\n",
    "\n",
    "        return (c1, sp1), (c2, sp2), target\n",
    "    \n",
    "    def normalize_speed(self, speed):\n",
    "        return (speed - self.mean_speed) / self.std_speed\n",
    "    \n",
    "    def normalize_coord(self, coord):\n",
    "        return (coord - self.mean_map) / self.std_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b31793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNetDataloader(DataLoader):\n",
    "    def __init__(self, dataset, *args, **kwargs):\n",
    "        super().__init__(dataset, collate_fn=self.collate_fn, *args, **kwargs)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        x_batch = []\n",
    "        speed_batch = []\n",
    "        x_lengths = []\n",
    "        ids = []\n",
    "        for id, x in enumerate(batch):\n",
    "            coord, speeds = x\n",
    "            x_batch.extend([torch.tensor(path, dtype=torch.float32) for path in coord])\n",
    "            speed_batch.extend(speeds)\n",
    "            x_lengths.extend([len(path) for path in coord])\n",
    "            ids.extend([id] * len(coord))\n",
    "        \n",
    "        padded_x = nn.utils.rnn.pad_sequence(x_batch, batch_first=True)\n",
    "        speed_tensor = torch.tensor(speed_batch, dtype=torch.float32)\n",
    "        ids_tensor = torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "        return padded_x, speed_tensor, x_lengths, ids_tensor\n",
    "\n",
    "\n",
    "class RankNetPairDataloader(DataLoader):\n",
    "    def collate_fn(self, batch):\n",
    "        x1, x2, targets = zip(*batch)\n",
    "        padded_x1, speed1, lengths1, ids1 = super().collate_fn(x1)\n",
    "        padded_x2, speed2, lengths2, ids2 = super().collate_fn(x2)\n",
    "        targets_tensor = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "        return (padded_x1, speed1, lengths1, ids1), (padded_x2, speed2, lengths2, ids2), targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super(RankNetModel, self).__init__()\n",
    "        self.phi = PathEncoder(input_dim, hidden_dim)\n",
    "        self.rho = AggregationNet(hidden_dim)\n",
    "\n",
    "    def forward(self, padded_x, speeds, lengths, ids):\n",
    "        path_embeddings = self.phi(padded_x, speeds, lengths)\n",
    "\n",
    "        unique_ids, inverse_indices = torch.unique(ids, return_inverse=True)\n",
    "        instance_embeddings = torch.zeros(len(unique_ids), path_embeddings.size(1)).to(path_embeddings.device)\n",
    "        instance_embeddings.index_add_(0, inverse_indices, path_embeddings)\n",
    "\n",
    "        scores = self.rho(instance_embeddings, unique_ids)\n",
    "        return scores\n",
    "\n",
    "\n",
    "class PathEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, padded_x, speeds, lengths):\n",
    "        packed_x = nn.utils.rnn.pack_padded_sequence(padded_x,\n",
    "                                                     lengths=lengths,\n",
    "                                                     batch_first=True,\n",
    "                                                     enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed_x)\n",
    "        ordered_h_n = h_n.index_select(1, packed_x.unsorted_indices)\n",
    "\n",
    "        speeds = speeds.unsqueeze(1)\n",
    "        h_n_combined = torch.cat((ordered_h_n[-1], speeds), dim=1)\n",
    "\n",
    "        return self.fc(h_n_combined)\n",
    "\n",
    "\n",
    "class AggregationNet(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, instance_embeddings):\n",
    "        aggregated = instance_embeddings.mean(dim=0, keepdim=True)\n",
    "        return self.fc(aggregated)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
